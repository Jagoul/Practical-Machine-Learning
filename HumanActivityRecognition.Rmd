---
title: "Practical Machine Learning - Human Activity Recognition"
author: "Raed Abdel Sater"
date: "November 12, 2017"
output:
  html_document: default
  pdf_document: default
  
---


Human Activity Recognition - HAR - has emerged as a key research area in the last years and is gaining increasing attention by the pervasive computing research community (see picture below, that illustrates the increasing number of publications in HAR with wearable accelerometers), especially for the development of context-aware systems. There are many potential applications for HAR, like: elderly monitoring, life log systems for monitoring energy expenditure and for supporting weight-loss programs, and digital assistants for weight lifting exercises.

In this project, data was used from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.

First we prepare the packages needed to load and manipulate data. along side to Caret and randomForcast, I used Hmisc to analyze data and doParallel package to decrease the random forest processing time by running parallel execution processing on Training data set. The seed value was set at the beginning of this project to garantee reproducible results

# Preparing and loading Datasets

```{r}
options(warn=-1)
library(caret)
library(randomForest)
library(Hmisc)

library(foreach)
library(doParallel)
set.seed(4356)
```

Second, we load CSV files as idicated in the instructions, in case files don't exist we download it in a specific directory and prepare it for analysis. Additional information about data type, size and completion rate are are commented below to limit the execution time and output size. You can run it individually by executing the uncommenting those lines

```{r}
setwd("/home/jagoul/Coursera/Data-Science-Specialization/Ptractical Machine Learning/Projects/Final Project/")
if (!file.exists("pmlTraining.csv")) {
    download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", 
                  destfile = "pmlTraining.csv")
}

if (!file.exists("pmlTesting.csv")) {
    download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", 
                  destfile = "pmlTesting.csv")
}
data <- read.csv("pmlTraining.csv")

#summary(data)
#describe(data)
#sapply(data, class)
#str(data)
```


# Data analysis

After observing the data we can deduce that some numeric data have been imported as factor,the presence of characters such as ("#DIV/0!") explain this observation. Also the fact that some columns have a really low completion rate, and consequently a lot of missing data values are present inside the data set.
 
To manage the factor issue,  we impute data while ignoring "#DIV/0!" values as follows:

```{r}
data <- read.csv("pmlTraining.csv", na.strings=c("#DIV/0!") )
```

Then run a numeric casting on all affected columns 
```{r}
cData <- data
for(i in c(8:ncol(cData)-1)) {cData[,i] = as.numeric(as.character(cData[,i]))}
```

As for the missing values, we select columns with a 100% completion rate as features, since the completion rate in this dataset is very binary, and we filter out some features which seem to be useless like "X"", timestamps, "new_window" and "num_window". We exclude also features that cannot be aggregated like user_name which limit the classifier to the name existing in our training dataset.

```{r}
featuresnames <- colnames(cData[colSums(is.na(cData)) == 0])[-(1:7)]
features <- cData[featuresnames]
```


Now we have a clean dataframe features which contains all useful information. We can split the dataset in two part : the first for training and the second for testing.

```{r}
xdata <- createDataPartition(y=features$classe, p=3/4, list=FALSE )
training <- features[xdata,]
testing <- features[-xdata,]
```


We can now create the model with the training data by running parallel processing with the foreach and doParallel package : we call registerDoParallel to instantiate the configuration. So we ask to process 4 random forest with 150 trees each and combine then to have a random forest model with a total of 600 trees.

```{r}
registerDoParallel()
model <- foreach(ntree=rep(150, 4), .combine=randomForest::combine) %dopar% randomForest(training[-ncol(training)], training$classe, ntree=ntree)
```

To evaluate the model we will use the confusionmatrix method and we will focus on accuracy, sensitivity & specificity metrics :

```{r}
predictionsTr <- predict(model, newdata=training)
confusionMatrix(predictionsTr,training$classe)


predictionsTe <- predict(model, newdata=testing)
confusionMatrix(predictionsTe,testing$classe)
```

# Interpretation

The result of the confusionmatrix now is ready, as we can see, the model is performance is quite good and efficient with an an accuracy of 0.997 and very good sensitivity & specificity values on the testing dataset. The lowest value is 0.993 for the sensitivity of the class C)


The results are quite impressive, the 20 predictable values has a score of 100% with 20 / 20 hits.